% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/perm_approx.R
\name{perm_approx}
\alias{perm_approx}
\title{Compute empirical and approximated p-values from permutation tests}
\usage{
perm_approx(
  obs_stats,
  perm_stats,
  method = "gpd",
  fit_thresh = 0.1,
  alternative = "two_sided",
  null_center = 0,
  power = 1,
  adjust_method = "BH",
  cores = 1,
  parallel_min = 10L,
  verbose = TRUE,
  gpd_ctrl = make_gpd_ctrl(),
  gamma_ctrl = make_gamma_ctrl(),
  adjust_ctrl = make_adjust_ctrl(),
  ...
)
}
\arguments{
\item{obs_stats}{Numeric vector of observed test statistic(s).}

\item{perm_stats}{Permutation test statistics. Should be provided as a 
numeric matrix or data frame with permutations in rows and tests in 
columns.}

\item{method}{Character. Method used to compute p-values. Default is
\code{"gpd"}. Options are:
\itemize{
  \item \code{"empirical"}: Empirical p-values are returned directly,
  based on the number of permutation test statistics that are as or
  more extreme than the observed statistic.
  \item \code{"gamma"}: A Gamma distribution is fitted to the permutation
    distribution if the empirical p-value falls below \code{fit_thresh}.
  \item \code{"gpd"}: A Generalized Pareto Distribution (GPD) is fitted
    to the tail of the permutation distribution if the empirical p-value
    falls below \code{fit_thresh}.
}}

\item{fit_thresh}{Numeric. Threshold on empirical p-values below which
parametric fitting is applied. Default: \code{0.1} (parametric
approximation if the empirical p-value is smaller than 0.1).}

\item{alternative}{Character. One of \code{"greater"}, \code{"less"}, or
\code{"two_sided"} (default), indicating the tail of the test.}

\item{null_center}{Numeric or character. Specifies the value around which the
null distribution is centered. If set to \code{"mean"} or \code{"median"},
the per-row mean or median of \code{perm_stats} is used instead.
This allows testing against a null hypothesis other than zero or centering
based on the empirical distribution.}

\item{power}{Numeric scalar. Optional monotone power transformation applied
to both permutation statistics and the observed statistic before threshold
detection and GPD fitting. Must be positive. 
Default: 1 (no transformation).}

\item{adjust_method}{Character. Method for multiple testing adjustment.
Options include:
\itemize{
  \item \code{"none"}: No adjustment.
  \item \code{"lfdr"}: Local false discovery rates via \code{fdrtool}.
  \item \code{"adapt_BH"}: Adaptive Benjamini-Hochberg (requires estimation
  of the proportion of true nulls).
  \item Any method supported by \code{stats::p.adjust} (e.g., "holm", "BH",
  "BY").
}}

\item{cores}{Integer >= 1. Number of CPU cores for parallel computations.
Default: 1.}

\item{parallel_min}{Integer. Minimum number of tests in a given
computation step (e.g., threshold detection, GPD/Gamma fitting, epsilon
refinement) for which parallel computation is used when \code{cores > 1}.
If the number of tests is smaller than \code{parallel_min}, the
corresponding step is run sequentially to avoid parallel overhead.
Default: \code{10}.}

\item{verbose}{Logical scalar. If \code{TRUE}, progress messages are printed.
Default: TRUE.}

\item{gpd_ctrl}{A control object created by \code{\link{make_gpd_ctrl}}.
Contains settings for the GPD approximation, such as the fitting method,
constraints, and thresholding strategy. Defaults to \code{make_gpd_ctrl()}.}

\item{gamma_ctrl}{A control object created by \code{\link{make_gamma_ctrl}}.
Contains settings for the Gamma approximation, including goodness-of-fit
test and inclusion of the observed statistic. Defaults to
\code{make_gamma_ctrl()}.}

\item{adjust_ctrl}{A control object created by \code{\link{make_adjust_ctrl}}.
Contains settings for multiple testing correction, such as the adjustment
method and estimation of the proportion of true null hypotheses.
Defaults to \code{make_adjust_ctrl()}.}

\item{...}{Additional arguments (currently unused).}
}
\value{
A list with the following components:

\describe{
  \item{\code{p_values}}{
    Numeric vector of final p-values. These are empirical p-values or,
    for tests where parametric tail approximation was successful,
    Gamma- or GPD-approximated p-values. If multiple testing correction
    was requested, \code{p_values} contains the adjusted p-values.
  }
  \item{\code{p_unadjusted}}{
    Numeric vector of unadjusted p-values, combining empirical and
    approximated values (where applicable).
  }
  \item{\code{p_empirical}}{
    Numeric vector of raw empirical p-values computed directly from the
    permutation distribution (before any approximation or adjustment).
  }
  \item{\code{fit_method}}{
    Character scalar indicating the parametric tail-approximation method
    used: one of \code{"gpd"}, \code{"gamma"}, or \code{"empirical"}.
    When \code{"empirical"}, no tail approximation was performed.
  }
  \item{\code{fit_result}}{
    A list containing the detailed output of the chosen tail-approximation
    method.  

    If \code{fit_method = "gpd"}, this is the result returned by
    \code{.compute_pvals_gpd()} (including GPD parameters, thresholds,
    exceedances, epsilon values, status flags, and fitted exceedances).

    If \code{fit_method = "gamma"}, this is the result returned by
    \code{.compute_pvals_gamma()} (including Gamma parameters,
    goodness-of-fit results, status flags, and permutation values used
    for the fit).  

    If \code{fit_method = "empirical"}, this entry is \code{NULL}.
  }
  \item{\code{method_used}}{
    Character vector of length \code{n_test}. For each hypothesis test,
    indicates whether the final p-value was empirical (\code{"empirical"})
    or came from Gamma or GPD approximation (\code{"gamma"} or \code{"gpd"}).
  }
  \item{\code{adjust_result}}{
    The full output of \code{mult_adjust()} if multiple testing correction
    was applied, otherwise \code{NULL}.
  }
  \item{\code{control}}{
    A list containing the control settings actually used in the computation,
    including the selected approximation control (Gamma or GPD) and the
    multiple testing adjustment control.
  }
}
}
\description{
Computes empirical p-values for permutation tests.
When p-values are small, a Gamma or Generalized Pareto Distribution
(GPD) is fitted to the (tail of the) permutation distribution to improve
resolution if the number of permutations is small.
}
\details{
For each test, \code{perm_approx()} first constructs a centered and,
optionally, transformed permutation distribution and then computes
empirical p-values. Parametric tail approximation (via Gamma or GPD) is
applied only for tests whose empirical p-value falls below
\code{fit_thresh}; all other tests remain purely empirical.

\subsection{Centering and transformation}{
The input permutation statistics \code{perm_stats} are organized with
permutations in rows and tests in columns. The observed statistics
\code{obs_stats} are aligned with the columns of \code{perm_stats}.

The null distribution is centered according to \code{null_center}:
\itemize{
  \item If \code{null_center} is numeric, the same value is subtracted
        from both \code{obs_stats} and \code{perm_stats}.
  \item If \code{null_center = "mean"} or \code{"median"}, the per-test
        mean or median of \code{perm_stats} is used as the centering
        value.
}
Centering is applied to both observed and permuted statistics.

Optionally, a monotone power transformation with exponent \code{power > 0}
is applied to all centered statistics. This can increase sensitivity in
the tail when the scale of the test statistic is highly skewed.

Finally, test statistics are transformed to a one-sided scale according
to \code{alternative} (\code{"greater"}, \code{"less"}, or
\code{"two_sided"}) via an internal helper function
\code{.transform_stats()}, so that all subsequent computations operate on
a common tail direction.
}

\subsection{Empirical p-values}{
Empirical p-values are computed for each test by comparing the observed
statistic to its permutation distribution on the transformed scale.
Specifically, if \eqn{r} denotes the number of permutation statistics
that are at least as extreme as the observed statistic (in the direction
defined by \code{alternative}) and \eqn{B} is the number of permutations,
the empirical p-value is
\deqn{
  \hat{p}_{\mathrm{emp}} = \frac{r + 1}{B + 1} \, .
}
This correction ensures that empirical p-values are never exactly zero.

These empirical p-values are always computed and returned in
\code{p_empirical}, regardless of the chosen \code{method}.
}

\subsection{Parametric tail approximation}{
If \code{method = "gpd"} or \code{"gamma"}, a parametric approximation
is applied only to tests with empirical p-values below
\code{fit_thresh}. The indices of these tests are passed to the
corresponding internal workhorse:
\itemize{
  \item \code{.compute_pvals_gpd()} for Generalized Pareto (GPD) tail
        approximation of the permutation distribution,
  \item \code{.compute_pvals_gamma()} for Gamma approximation of the full
        permutation distribution.
}

Both functions return a list with one entry per test (see their
respective documentation), including approximated tail p-values and
diagnostic information such as fitted parameters, goodness-of-fit
p-values, and per-test status flags. This list is returned as
\code{fit_result}, and the chosen approximation is indicated by
\code{fit_method} (\code{"gpd"} or \code{"gamma"}). If
\code{method = "empirical"} or no tests satisfy the threshold
\code{fit_thresh}, \code{fit_method = "empirical"} and
\code{fit_result} is \code{NULL}.

For tests where the parametric fit is deemed successful
(typically those with \code{status == "success"} in \code{fit_result}),
the empirical p-value is replaced by the approximated tail p-value.
For all other tests, the empirical p-value is retained. The resulting
mixture of empirical and approximated p-values is returned in
\code{p_unadjusted}. The per-test origin of the final p-value is tracked
in \code{method_used}, indicating \code{"empirical"}, \code{"gamma"}, or
\code{"gpd"} for each test.
}

\subsection{Multiple testing adjustment}{
If \code{adjust_method = "none"}, no multiple testing correction is
applied, and \code{p_values} is identical to \code{p_unadjusted}.
Otherwise, \code{p_values} contains multiplicity-adjusted p-values
obtained by calling \code{mult_adjust()} with the specified adjustment
method and control parameters in \code{adjust_ctrl}. The full output of
\code{mult_adjust()} is returned in \code{adjust_result}.

The \code{control} element in the output collects the control settings
actually used for tail approximation (GPD or Gamma) and multiple testing
adjustment, which facilitates reproducibility and downstream inspection.
}
}
\examples{

## ---------------------------------------------------------------------
## 10 tests, one truly non-null (two-sample mean differences)
## ---------------------------------------------------------------------

set.seed(42)

n_per_group <- 50
m_tests     <- 10

# Group labels: 0 = control, 1 = treatment
group <- rep(c(0, 1), each = n_per_group)

# Data matrix: rows = samples, cols = tests/features
X <- matrix(
  rnorm(2 * n_per_group * m_tests, mean = 0, sd = 1),
  ncol = m_tests
)

# Introduce a true effect in the first test (column 1)
X[group == 1, 1] <- X[group == 1, 1] + 0.8

# Observed test statistics: difference in means (treated - control)
obs_stats <- colMeans(X[group == 1, , drop = FALSE]) -
             colMeans(X[group == 0, , drop = FALSE])

# Permutation distribution: shuffle group labels and recompute all 10 stats
B <- 500
perm_mat <- matrix(NA_real_, nrow = B, ncol = m_tests)

for (b in seq_len(B)) {
  grp_perm <- sample(group)
  perm_mat[b, ] <- colMeans(X[grp_perm == 1, , drop = FALSE]) -
                   colMeans(X[grp_perm == 0, , drop = FALSE])
}

# Empirical p-values only (BH-adjusted by default)
res_emp <- perm_approx(
  obs_stats  = obs_stats,
  perm_stats = perm_mat,
  method     = "empirical",
  verbose    = FALSE
)

# Adjusted p-values (BH by default)
res_emp$p_values

# Unadjusted p-values
res_emp$p_unadjusted


## ---------------------------------------------------------------------
## GPD approximation for the same 10 tests
## ---------------------------------------------------------------------

# GPD-related arguments are changed using make_gpd_ctrl()
gpd_ctrl <- make_gpd_ctrl(
  constraint  = "support_at_obs",
  sample_size = n_per_group
)

# Run p-value approximation
res_gpd <- perm_approx(
  obs_stats  = obs_stats,
  perm_stats = perm_mat,
  method     = "gpd",
  gpd_ctrl   = gpd_ctrl,
  verbose    = FALSE
)

# Tail fit details
fit <- res_gpd$fit_result
fit$status      # success / discrete / fit_failed / gof_reject
fit$shape       # GPD shape estimates per test
fit$thresh      # thresholds
fit$n_exceed    # number of exceedances

# Compare empirical vs approximated (unadjusted) p-values
emp_gpd_df <- data.frame(
  empirical = res_emp$p_unadjusted,
  GPD       = res_gpd$p_unadjusted
)
emp_gpd_df


## ---------------------------------------------------------------------
## Multiple testing adjustment with adapt_BH
## ---------------------------------------------------------------------

# Adaptive BH method for multiple testing adjustment
adjust_ctrl <- make_adjust_ctrl(true_null_method = "lfdr")

res_adapt_BH <- perm_approx(
  obs_stats     = obs_stats,
  perm_stats    = perm_mat,
  method        = "gpd",
  gpd_ctrl      = gpd_ctrl,
  adjust_method = "adapt_BH",
  adjust_ctrl   = adjust_ctrl,
  verbose       = FALSE
)

# Adjusted vs. unadjusted p-values
adj_unadj_df <- data.frame(
  GPD_unadjusted = res_gpd$p_unadjusted,
  GPD_adjusted   = res_adapt_BH$p_values
)
adj_unadj_df

}
